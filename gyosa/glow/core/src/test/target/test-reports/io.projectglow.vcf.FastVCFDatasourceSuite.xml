<?xml version='1.0' encoding='UTF-8'?>
<testsuite hostname="cloud122" name="io.projectglow.vcf.FastVCFDatasourceSuite" tests="49" errors="0" failures="3" skipped="0" time="4.106" timestamp="2023-11-03T13:37:58">
                     <properties>
      <property name="jline.esc.timeout" value="0"/><property name="jna.platform.library.path" value="/usr/lib/x86_64-linux-gnu:/lib/x86_64-linux-gnu:/lib64:/usr/lib:/lib:/usr/lib/x86_64-linux-gnu/libfakeroot"/><property name="java.runtime.name" value="Java(TM) SE Runtime Environment"/><property name="sun.boot.library.path" value="/usr/lib/jvm/jdk1.8.0_211/jre/lib/amd64"/><property name="java.vm.version" value="25.211-b12"/><property name="java.vm.vendor" value="Oracle Corporation"/><property name="java.vendor.url" value="http://java.oracle.com/"/><property name="path.separator" value=":"/><property name="jna.loaded" value="true"/><property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM"/><property name="file.encoding.pkg" value="sun.io"/><property name="user.country" value="US"/><property name="sun.java.launcher" value="SUN_STANDARD"/><property name="sun.os.patch.level" value="unknown"/><property name="jna.nosys" value="true"/><property name="java.vm.specification.name" value="Java Virtual Machine Specification"/><property name="user.dir" value="/home/gsd/gyosa/glow"/><property name="java.runtime.version" value="1.8.0_211-b12"/><property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/><property name="java.endorsed.dirs" value="/usr/lib/jvm/jdk1.8.0_211/jre/lib/endorsed"/><property name="os.arch" value="amd64"/><property name="java.io.tmpdir" value="/tmp"/><property name="line.separator" value="
"/><property name="java.vm.specification.vendor" value="Oracle Corporation"/><property name="java.util.logging.manager" value="wvlet.log.AirframeLogManager"/><property name="log4j.ignoreTCL" value="true"/><property name="os.name" value="Linux"/><property name="sun.jnu.encoding" value="ISO-8859-1"/><property name="jnidispatch.path" value="/tmp/jna-102648/jna1976320173356081238.tmp"/><property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/><property name="java.specification.name" value="Java Platform API Specification"/><property name="java.class.version" value="52.0"/><property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/><property name="os.version" value="4.15.0-202-generic"/><property name="swoval.tmpdir" value="/home/gsd/.sbt/1.0"/><property name="user.home" value="/home/gsd"/><property name="user.timezone" value="Europe/Lisbon"/><property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/><property name="file.encoding" value="UTF-8"/><property name="java.specification.version" value="1.8"/><property name="java.class.path" value="/home/gsd/.cache/sbt/boot/sbt-launch/1.8.2/sbt-launch-1.8.2.jar"/><property name="user.name" value="gsd"/><property name="jline.shutdownhook" value="false"/><property name="java.vm.specification.version" value="1.8"/><property name="sun.java.command" value="/home/gsd/.cache/sbt/boot/sbt-launch/1.8.2/sbt-launch-1.8.2.jar"/><property name="java.home" value="/usr/lib/jvm/jdk1.8.0_211/jre"/><property name="sun.arch.data.model" value="64"/><property name="user.language" value="en"/><property name="java.specification.vendor" value="Oracle Corporation"/><property name="awt.toolkit" value="sun.awt.X11.XToolkit"/><property name="java.vm.info" value="mixed mode"/><property name="java.version" value="1.8.0_211"/><property name="java.ext.dirs" value="/usr/lib/jvm/jdk1.8.0_211/jre/lib/ext:/usr/java/packages/lib/ext"/><property name="sun.boot.class.path" value="/usr/lib/jvm/jdk1.8.0_211/jre/lib/resources.jar:/usr/lib/jvm/jdk1.8.0_211/jre/lib/rt.jar:/usr/lib/jvm/jdk1.8.0_211/jre/lib/sunrsasign.jar:/usr/lib/jvm/jdk1.8.0_211/jre/lib/jsse.jar:/usr/lib/jvm/jdk1.8.0_211/jre/lib/jce.jar:/usr/lib/jvm/jdk1.8.0_211/jre/lib/charsets.jar:/usr/lib/jvm/jdk1.8.0_211/jre/lib/jfr.jar:/usr/lib/jvm/jdk1.8.0_211/jre/classes"/><property name="java.vendor" value="Oracle Corporation"/><property name="file.separator" value="/"/><property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/><property name="sun.io.unicode.encoding" value="UnicodeLittle"/><property name="sun.cpu.endian" value="little"/><property name="sbt.script" value="/usr/bin/sbt"/><property name="sun.cpu.isalist" value=""/>
    </properties>
                     <testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="default schema" time="0.081">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="parse VCF" time="0.064">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="no sample ids" time="0.036">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="with sample ids" time="0.112">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="check parsed row" time="0.138">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="multiple genotype fields" time="0.065">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="filter with and without pushdown returns same results" time="0.443">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="uncalled genotype" time="0.062">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="uncalled diploid genotype" time="0.051">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="phased genotype" time="0.063">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="unphased genotype" time="0.053">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="info field flags" time="0.052">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="missing info values" time="0.101">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="missing format values" time="0.063">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="dropped trailing format values" time="0.053">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="missing GT format field" time="0.088">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="missing calls are -1 (zero present" time="0.054">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="missing calls are -1 (only one present)" time="0.132">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="set END field" time="0.052">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="3" time="0.056">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="splitToBiallelic option error message" time="0.036">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="strict validation stringency" time="0.064">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="validation stringency (format fields)" time="0.204">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="invalid validation stringency" time="0.003">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="check parsed row with flattened INFO fields" time="0.142">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="flattened INFO fields schema does not include END key" time="0.033">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="flattened INFO fields schema merged for multiple files" time="0.033">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="prune a flattened INFO field" time="0.097">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="parse string INFO fields" time="0.066">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="partitioned file without all of header" time="0.01">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="gzip splits are only read if they contain the beginning of the file" time="0.517">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="misnumbered fields" time="0.067">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="multiple rows" time="0.116">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="infer non standard format fields" time="0.119">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="be permissive if schema includes fields that can't be derived from VCF" time="0.038">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="add BGZ codec when reading VCF" time="0.001">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="uncompressed files are splitable" time="0.0">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Tolerate lower-case nan's" time="0.061">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Parse VEP" time="0.128">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Parse SnpEff" time="0.097">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Do not break when reading index file" time="0.029">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Do not break when reading directory with index files" time="0.033">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Do not break when reading VCFs with contig lines missing length" time="0.03">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="prune genotype fields" time="0.069">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="read AD with nulls" time="0.062">
                                                 
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Tolerate inf" time="0.056">
                                                 <failure message="org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 164.0 failed 1 times, most recent failure: Lost task 0.0 in stage 164.0 (TID 451) (192.168.112.122 executor driver): java.lang.NumberFormatException: For input string: &quot;infinity&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.LineCtx.parseDouble(VCFLineToInternalRowConverter.scala:407)
	at io.projectglow.vcf.VCFLineToInternalRowConverter.convert(VCFLineToInternalRowConverter.scala:171)
	at io.projectglow.vcf.VCFFileFormat.$anonfun$buildReader$11(VCFFileFormat.scala:222)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:512)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:" type="sbt.ForkMain$ForkError">sbt.ForkMain$ForkError: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 164.0 failed 1 times, most recent failure: Lost task 0.0 in stage 164.0 (TID 451) (192.168.112.122 executor driver): java.lang.NumberFormatException: For input string: &quot;infinity&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.LineCtx.parseDouble(VCFLineToInternalRowConverter.scala:407)
	at io.projectglow.vcf.VCFLineToInternalRowConverter.convert(VCFLineToInternalRowConverter.scala:171)
	at io.projectglow.vcf.VCFFileFormat.$anonfun$buildReader$11(VCFFileFormat.scala:222)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:512)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)
	at scala.Option.foreach(Option.scala:274)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1020)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:424)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)
	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3120)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:3120)
	at io.projectglow.vcf.FastVCFDatasourceSuite.$anonfun$new$57(VCFDatasourceSuite.scala:792)
	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:190)
	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)
	at org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1563)
	at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:188)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:200)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:200)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:182)
	at io.projectglow.sql.GlowBaseTest.org$scalatest$BeforeAndAfterEach$$super$runTest(GlowBaseTest.scala:29)
	at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)
	at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)
	at io.projectglow.sql.GlowBaseTest.runTest(GlowBaseTest.scala:63)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:233)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:232)
	at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1563)
	at org.scalatest.Suite.run(Suite.scala:1112)
	at org.scalatest.Suite.run$(Suite.scala:1094)
	at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1563)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:237)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
	at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:237)
	at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:236)
	at io.projectglow.sql.GlowBaseTest.org$scalatest$BeforeAndAfterAll$$super$run(GlowBaseTest.scala:29)
	at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)
	at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)
	at io.projectglow.sql.GlowBaseTest.run(GlowBaseTest.scala:29)
	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)
	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:304)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: sbt.ForkMain$ForkError: java.lang.NumberFormatException: For input string: &quot;infinity&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.LineCtx.parseDouble(VCFLineToInternalRowConverter.scala:407)
	at io.projectglow.vcf.VCFLineToInternalRowConverter.convert(VCFLineToInternalRowConverter.scala:171)
	at io.projectglow.vcf.VCFFileFormat.$anonfun$buildReader$11(VCFFileFormat.scala:222)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:512)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	... 3 more
</failure>
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Tolerate genotype inf" time="0.068">
                                                 <failure message="org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 167.0 failed 1 times, most recent failure: Lost task 0.0 in stage 167.0 (TID 456) (192.168.112.122 executor driver): java.lang.IllegalArgumentException: Could not parse FORMAT field GP. Exception: For input string: &quot;inf&quot;
	at io.projectglow.common.HasStringency.raiseValidationError(HasStringency.scala:25)
	at io.projectglow.common.HasStringency.raiseValidationError$(HasStringency.scala:23)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.raiseValidationError(VariantContextToInternalRowConverter.scala:50)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:176)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.updateFormatField(VariantContextToInternalRowConverter.scala:443)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12$adapted(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13(VariantContextToInternalRowConverter.scala:90)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13$adapted(VariantContextToInternalRowConverter.scala:84)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.convertRow(VariantContextToInternalRowConverter.scala:146)
	at io.projectglow.vcf.SchemaDelegate$NormalDelegate.$anonfun$toRows$1(VCFFileFormat.scala:463)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.next(FileScanRDD.scala:189)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: &quot;inf&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$4(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.obj2any(VariantContextToInternalRowConverter.scala:529)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$1(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:170)
	... 32 more

Driver stacktrace:" type="sbt.ForkMain$ForkError">sbt.ForkMain$ForkError: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 167.0 failed 1 times, most recent failure: Lost task 0.0 in stage 167.0 (TID 456) (192.168.112.122 executor driver): java.lang.IllegalArgumentException: Could not parse FORMAT field GP. Exception: For input string: &quot;inf&quot;
	at io.projectglow.common.HasStringency.raiseValidationError(HasStringency.scala:25)
	at io.projectglow.common.HasStringency.raiseValidationError$(HasStringency.scala:23)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.raiseValidationError(VariantContextToInternalRowConverter.scala:50)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:176)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.updateFormatField(VariantContextToInternalRowConverter.scala:443)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12$adapted(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13(VariantContextToInternalRowConverter.scala:90)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13$adapted(VariantContextToInternalRowConverter.scala:84)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.convertRow(VariantContextToInternalRowConverter.scala:146)
	at io.projectglow.vcf.SchemaDelegate$NormalDelegate.$anonfun$toRows$1(VCFFileFormat.scala:463)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.next(FileScanRDD.scala:189)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: &quot;inf&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$4(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.obj2any(VariantContextToInternalRowConverter.scala:529)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$1(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:170)
	... 32 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)
	at scala.Option.foreach(Option.scala:274)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:2863)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3084)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:327)
	at org.apache.spark.sql.Dataset.show(Dataset.scala:808)
	at org.apache.spark.sql.Dataset.show(Dataset.scala:767)
	at org.apache.spark.sql.Dataset.show(Dataset.scala:776)
	at io.projectglow.vcf.FastVCFDatasourceSuite.$anonfun$new$58(VCFDatasourceSuite.scala:826)
	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:190)
	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)
	at org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1563)
	at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:188)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:200)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:200)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:182)
	at io.projectglow.sql.GlowBaseTest.org$scalatest$BeforeAndAfterEach$$super$runTest(GlowBaseTest.scala:29)
	at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)
	at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)
	at io.projectglow.sql.GlowBaseTest.runTest(GlowBaseTest.scala:63)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:233)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:232)
	at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1563)
	at org.scalatest.Suite.run(Suite.scala:1112)
	at org.scalatest.Suite.run$(Suite.scala:1094)
	at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1563)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:237)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
	at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:237)
	at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:236)
	at io.projectglow.sql.GlowBaseTest.org$scalatest$BeforeAndAfterAll$$super$run(GlowBaseTest.scala:29)
	at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)
	at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)
	at io.projectglow.sql.GlowBaseTest.run(GlowBaseTest.scala:29)
	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)
	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:304)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: sbt.ForkMain$ForkError: java.lang.IllegalArgumentException: Could not parse FORMAT field GP. Exception: For input string: &quot;inf&quot;
	at io.projectglow.common.HasStringency.raiseValidationError(HasStringency.scala:25)
	at io.projectglow.common.HasStringency.raiseValidationError$(HasStringency.scala:23)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.raiseValidationError(VariantContextToInternalRowConverter.scala:50)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:176)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.updateFormatField(VariantContextToInternalRowConverter.scala:443)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12$adapted(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13(VariantContextToInternalRowConverter.scala:90)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13$adapted(VariantContextToInternalRowConverter.scala:84)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.convertRow(VariantContextToInternalRowConverter.scala:146)
	at io.projectglow.vcf.SchemaDelegate$NormalDelegate.$anonfun$toRows$1(VCFFileFormat.scala:463)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.next(FileScanRDD.scala:189)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	... 3 more
Caused by: sbt.ForkMain$ForkError: java.lang.NumberFormatException: For input string: &quot;inf&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$4(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.obj2any(VariantContextToInternalRowConverter.scala:529)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$1(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:170)
	... 32 more
</failure>
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="Tolerate genotype nan" time="0.058">
                                                 <failure message="org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 170.0 failed 1 times, most recent failure: Lost task 0.0 in stage 170.0 (TID 461) (192.168.112.122 executor driver): java.lang.IllegalArgumentException: Could not parse FORMAT field GP. Exception: For input string: &quot;Nan&quot;
	at io.projectglow.common.HasStringency.raiseValidationError(HasStringency.scala:25)
	at io.projectglow.common.HasStringency.raiseValidationError$(HasStringency.scala:23)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.raiseValidationError(VariantContextToInternalRowConverter.scala:50)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:176)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.updateFormatField(VariantContextToInternalRowConverter.scala:443)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12$adapted(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13(VariantContextToInternalRowConverter.scala:90)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13$adapted(VariantContextToInternalRowConverter.scala:84)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.convertRow(VariantContextToInternalRowConverter.scala:146)
	at io.projectglow.vcf.SchemaDelegate$NormalDelegate.$anonfun$toRows$1(VCFFileFormat.scala:463)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.next(FileScanRDD.scala:189)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: &quot;Nan&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$4(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.obj2any(VariantContextToInternalRowConverter.scala:529)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$1(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:170)
	... 32 more

Driver stacktrace:" type="sbt.ForkMain$ForkError">sbt.ForkMain$ForkError: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 170.0 failed 1 times, most recent failure: Lost task 0.0 in stage 170.0 (TID 461) (192.168.112.122 executor driver): java.lang.IllegalArgumentException: Could not parse FORMAT field GP. Exception: For input string: &quot;Nan&quot;
	at io.projectglow.common.HasStringency.raiseValidationError(HasStringency.scala:25)
	at io.projectglow.common.HasStringency.raiseValidationError$(HasStringency.scala:23)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.raiseValidationError(VariantContextToInternalRowConverter.scala:50)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:176)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.updateFormatField(VariantContextToInternalRowConverter.scala:443)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12$adapted(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13(VariantContextToInternalRowConverter.scala:90)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13$adapted(VariantContextToInternalRowConverter.scala:84)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.convertRow(VariantContextToInternalRowConverter.scala:146)
	at io.projectglow.vcf.SchemaDelegate$NormalDelegate.$anonfun$toRows$1(VCFFileFormat.scala:463)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.next(FileScanRDD.scala:189)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NumberFormatException: For input string: &quot;Nan&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$4(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.obj2any(VariantContextToInternalRowConverter.scala:529)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$1(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:170)
	... 32 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)
	at scala.Option.foreach(Option.scala:274)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:2863)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3084)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:327)
	at org.apache.spark.sql.Dataset.show(Dataset.scala:808)
	at org.apache.spark.sql.Dataset.show(Dataset.scala:767)
	at org.apache.spark.sql.Dataset.show(Dataset.scala:776)
	at io.projectglow.vcf.FastVCFDatasourceSuite.$anonfun$new$59(VCFDatasourceSuite.scala:860)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:190)
	at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)
	at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)
	at org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1563)
	at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:188)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:200)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:200)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:182)
	at io.projectglow.sql.GlowBaseTest.org$scalatest$BeforeAndAfterEach$$super$runTest(GlowBaseTest.scala:29)
	at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)
	at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)
	at io.projectglow.sql.GlowBaseTest.runTest(GlowBaseTest.scala:63)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:233)
	at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:232)
	at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1563)
	at org.scalatest.Suite.run(Suite.scala:1112)
	at org.scalatest.Suite.run$(Suite.scala:1094)
	at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1563)
	at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:237)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
	at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:237)
	at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:236)
	at io.projectglow.sql.GlowBaseTest.org$scalatest$BeforeAndAfterAll$$super$run(GlowBaseTest.scala:29)
	at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)
	at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)
	at io.projectglow.sql.GlowBaseTest.run(GlowBaseTest.scala:29)
	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)
	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:304)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: sbt.ForkMain$ForkError: java.lang.IllegalArgumentException: Could not parse FORMAT field GP. Exception: For input string: &quot;Nan&quot;
	at io.projectglow.common.HasStringency.raiseValidationError(HasStringency.scala:25)
	at io.projectglow.common.HasStringency.raiseValidationError$(HasStringency.scala:23)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.raiseValidationError(VariantContextToInternalRowConverter.scala:50)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:176)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.updateFormatField(VariantContextToInternalRowConverter.scala:443)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeGenotypeConverter$12$adapted(VariantContextToInternalRowConverter.scala:132)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13(VariantContextToInternalRowConverter.scala:90)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$makeConverter$13$adapted(VariantContextToInternalRowConverter.scala:84)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:41)
	at io.projectglow.sql.util.RowConverter.apply(RowConverter.scala:34)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.convertRow(VariantContextToInternalRowConverter.scala:146)
	at io.projectglow.vcf.SchemaDelegate$NormalDelegate.$anonfun$toRows$1(VCFFileFormat.scala:463)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.next(FileScanRDD.scala:189)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	... 3 more
Caused by: sbt.ForkMain$ForkError: java.lang.NumberFormatException: For input string: &quot;Nan&quot;
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike.toDouble(StringLike.scala:321)
	at scala.collection.immutable.StringLike.toDouble$(StringLike.scala:321)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:33)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$4(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.obj2any(VariantContextToInternalRowConverter.scala:529)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.$anonfun$updateFormatField$1(VariantContextToInternalRowConverter.scala:447)
	at io.projectglow.vcf.VariantContextToInternalRowConverter.tryWithWarning(VariantContextToInternalRowConverter.scala:170)
	... 32 more
</failure>
                                               </testcase><testcase classname="io.projectglow.vcf.FastVCFDatasourceSuite" name="read string that starts with " time="0.05">
                                                 
                                               </testcase>
                     <system-out><![CDATA[]]></system-out>
                     <system-err><![CDATA[]]></system-err>
                   </testsuite>